{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDyLVfiKrLfiQQjCGPPuvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datafilik/mobile-nextgen-wireless-comms-rsrch/blob/master/autoencoderMimoOfdmSystemv1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHLCu74Bt379",
        "outputId": "a99d00f4-c8be-4471-9bb7-3772d2eb625d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPUs available : 0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Created on Sat Oct 22 18:01:37 2022\n",
        "@Title: learning based end-to-end MIMO OFDM system using autoencoders\n",
        "@author: v1k18ty8\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
        "# For more details, see https://www.tensorflow.org/guide/gpu\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print('Number of GPUs available :', len(gpus))\n",
        "if gpus:\n",
        "    gpu_num = 0 # Index of the GPU to use\n",
        "    try:\n",
        "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
        "        print('Only GPU number', gpu_num, 'used.')\n",
        "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer, Dense\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna\n",
        "except ImportError as e:\n",
        "    # Install Sionna if package is not already installed\n",
        "    import os\n",
        "    os.system(\"pip install sionna\")\n",
        "    import sionna\n",
        "\n",
        "\n",
        "from sionna.channel.tr38901 import Antenna, AntennaArray, CDL\n",
        "from sionna.channel import OFDMChannel\n",
        "from sionna.mimo import StreamManagement\n",
        "from sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper\n",
        "from sionna.utils import BinarySource, ebnodb2no, insert_dims, flatten_last_dims, log10, expand_to_rank\n",
        "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
        "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
        "from sionna.mapping import Mapper, Demapper, Constellation\n",
        "from sionna.utils.metrics import compute_ber\n",
        "from sionna.utils import sim_ber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simulation parameters\n",
        "################################################\n",
        "# Channel configuration\n",
        "################################################\n",
        "carrier_frequency = 28e9 # Hz\n",
        "delay_spread = 100e-9 # s\n",
        "cdl_model = \"C\" # CDL model to use\n",
        "###############################################\n",
        "# SNR range for evaluation and training [dB]\n",
        "###############################################\n",
        "ebno_db_min = 5.0\n",
        "ebno_db_max = 8.0\n",
        "\n",
        "############################################\n",
        "## OFDM waveform configuration\n",
        "############################################\n",
        "subcarrier_spacing = 30e3 # Hz\n",
        "fft_size = 128 # Number of subcarriers forming the resource grid, including the null-subcarrier and the guard bands\n",
        "num_ofdm_symbols = 14 # Number of OFDM symbols forming the resource grid\n",
        "dc_null = True # Null the DC subcarrier\n",
        "num_guard_carriers = [5, 6] # Number of guard carriers on each side\n",
        "pilot_pattern = \"kronecker\" # Pilot pattern\n",
        "pilot_ofdm_symbol_indices = [2, 11] # Index of OFDM symbols carrying pilots\n",
        "cyclic_prefix_length = 0 # Simulation in frequency domain. This is useless\n",
        "\n",
        "###############################################\n",
        "# Modulation and coding configuration\n",
        "###############################################\n",
        "num_bits_per_symbol = 6 # Baseline is 64-QAM\n",
        "modulation_order = 2**num_bits_per_symbol\n",
        "coderate = 0.5 # Coderate for the outer code\n",
        "n = 1500 # Codeword length [bit]. Must be a multiple of num_bits_per_symbol\n",
        "num_symbols_per_codeword = n//num_bits_per_symbol # Number of modulated baseband symbols per codeword\n",
        "k = int(n*coderate) # Number of information bits per codeword\n",
        "\n",
        "###############################################\n",
        "# Training configuration\n",
        "###############################################\n",
        "num_training_iterations_conventional = 100 #10000 # Number of training iterations for conventional training\n",
        "# Number of training iterations with RL-based training for the alternating training phase and fine-tuning of the receiver phase\n",
        "num_training_iterations_rl_alt = 70 #7000\n",
        "num_training_iterations_rl_finetuning = 30 #3000\n",
        "training_batch_size = tf.constant(128, tf.int32) # Training batch size\n",
        "rl_perturbation_var = 0.01 # Variance of the perturbation used for RL-based training of the transmitter\n",
        "model_weights_path_conventional_training = \"awgn_autoencoder_weights_conventional_training\" # Filename to save the autoencoder weights once conventional training is done\n",
        "model_weights_path_rl_training = \"awgn_autoencoder_weights_rl_training\" # Filename to save the autoencoder weights once RL-based training is done\n",
        "\n",
        "###############################################\n",
        "# Evaluation configuration\n",
        "###############################################\n",
        "results_filename = \"awgn_autoencoder_results\" # Location to save the results\n",
        "\n",
        "stream_manager = StreamManagement(np.array([[1]]),1) # Receiver-transmitter association matrix. One stream per transmitter\n",
        "\n",
        "resource_grid = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n",
        "                             fft_size = fft_size,\n",
        "                             subcarrier_spacing = subcarrier_spacing,\n",
        "                             num_tx = 1,\n",
        "                             num_streams_per_tx = 1,\n",
        "                             cyclic_prefix_length = cyclic_prefix_length,\n",
        "                             dc_null = dc_null,\n",
        "                             pilot_pattern = pilot_pattern,\n",
        "                             pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices,\n",
        "                             num_guard_carriers = num_guard_carriers)\n",
        "\n",
        "# Codeword length. It is calculated from the total number of databits carried by the resource grid, and the number of bits transmitted per resource element\n",
        "n = int(resource_grid.num_data_symbols*num_bits_per_symbol)\n",
        "# Number of information bits per codeword\n",
        "k = int(n*coderate)\n",
        "\n",
        "ut_antenna = Antenna(polarization=\"single\",\n",
        "                     polarization_type=\"V\",\n",
        "                     antenna_pattern=\"38.901\",\n",
        "                     carrier_frequency=carrier_frequency)\n",
        "\n",
        "bs_array = AntennaArray(num_rows=1,\n",
        "                        num_cols=1,\n",
        "                        polarization=\"dual\",\n",
        "                        polarization_type=\"VH\",\n",
        "                        antenna_pattern=\"38.901\",\n",
        "                        carrier_frequency=carrier_frequency)\n"
      ],
      "metadata": {
        "id": "zhi8Se4luNkb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralDemapper(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self._dense_1 = Dense(128, 'relu')\n",
        "        self._dense_2 = Dense(128, 'relu')\n",
        "        self._dense_3 = Dense(num_bits_per_symbol, None) # The feature correspond to the LLRs for every bits carried by a symbol\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y,no = inputs\n",
        "\n",
        "        # Using log10 scale helps with the performance\n",
        "        no_db = log10(no)\n",
        "\n",
        "        # Stacking the real and imaginary components of the complex received samples\n",
        "        # and the noise variance\n",
        "        no_db = tf.tile(no_db, [1, num_symbols_per_codeword]) # [batch size, num_symbols_per_codeword]\n",
        "        z = tf.stack([tf.math.real(y),\n",
        "                      tf.math.imag(y),\n",
        "                      no_db], axis=2) # [batch size, num_symbols_per_codeword, 3]\n",
        "        llr = self._dense_1(z)\n",
        "        llr = self._dense_2(llr)\n",
        "        llr = self._dense_3(llr) # [batch size, num_symbols_per_codeword, num_bits_per_symbol]\n",
        "\n",
        "        return llr\n"
      ],
      "metadata": {
        "id": "DD4b6zEBuq5V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class E2ESystemConventionalTraining(Model):\n",
        "\n",
        "    def __init__(self, speed, training):\n",
        "        super().__init__()\n",
        "\n",
        "        self._training = training\n",
        "\n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        self._binary_source = BinarySource()\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._encoder = LDPC5GEncoder(k, n)\n",
        "        # Trainable constellation\n",
        "        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n",
        "        self.constellation = constellation\n",
        "        self._mapper = Mapper(constellation=constellation)\n",
        "        # mod for OFDM\n",
        "        self._rg_mapper = ResourceGridMapper(resource_grid)\n",
        "\n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        #self._channel = AWGN()\n",
        "        # A 3GPP CDL channel model is used\n",
        "        cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n",
        "                  ut_antenna, bs_array, \"uplink\", min_speed=speed)\n",
        "        self._channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        # We use the previously defined neural network for demapping\n",
        "        self._demapper = NeuralDemapper()\n",
        "        self._rg_demapper = ResourceGridDemapper(resource_grid, stream_manager) # Used to extract data-carrying resource elements\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
        "\n",
        "        #################\n",
        "        # Loss function\n",
        "        #################\n",
        "        if self._training:\n",
        "            self._bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    #@tf.function\n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n",
        "        if len(ebno_db.shape) == 0:\n",
        "            ebno_db = tf.fill([batch_size], ebno_db)\n",
        "        #no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, resource_grid)\n",
        "        #no = expand_to_rank(no, 2)\n",
        "\n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        # Outer coding is only performed if not training\n",
        "        if self._training:\n",
        "            #c = self._binary_source([batch_size, n])\n",
        "            c = self._binary_source([batch_size, 1,1, n])\n",
        "        else:\n",
        "            #b = self._binary_source([batch_size, k])\n",
        "            b = self._binary_source([batch_size,1,1, k])\n",
        "            c = self._encoder(b)\n",
        "        # Modulation\n",
        "        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n",
        "        x_rg = self._rg_mapper(x)\n",
        "\n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        # A batch of new channel realizations is sampled and applied at every inference\n",
        "        no_ = expand_to_rank(no, tf.rank(x_rg))\n",
        "        y = self._channel([x_rg, no_]) # [batch size, num_symbols_per_codeword]\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        #llr = self._demapper([y, no])\n",
        "        #llr = tf.reshape(llr, [batch_size, n])\n",
        "        \n",
        "        # The neural receover computes LLRs from the frequency domain received symbols and N0\n",
        "        # y = tf.squeeze(y, axis=1)\n",
        "        # llr = self._neural_receiver([y, no])\n",
        "        # llr = insert_dims(llr, 2, 1) # Reshape the input to fit what the resource grid demapper is expected\n",
        "        llr = self._rg_demapper([y, no_]) # Extract data-carrying resource elements. The other LLrs are discarded\n",
        "        llr = tf.reshape(llr, [batch_size, 1, 1, n]) # Reshape the LLRs to fit what the outer decoder is expected\n",
        "        \n",
        "        # If training, outer decoding is not performed and the BCE is returned\n",
        "        if self._training:\n",
        "            loss = self._bce(c, llr)\n",
        "            return loss\n",
        "        else:\n",
        "            # Outer decoding\n",
        "            b_hat = self._decoder(llr)\n",
        "            return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n",
        "                \n",
        "def conventional_training(model):\n",
        "    # Optimizer used to apply gradients\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    for i in range(num_training_iterations_conventional):\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = model(training_batch_size, ebno_db) # The model is assumed to return the BMD rate\n",
        "        # Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(loss, weights)\n",
        "        optimizer.apply_gradients(zip(grads, weights))\n",
        "        # Printing periodically the progress\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  BCE: {:.4f}'.format(i, num_training_iterations_conventional, loss.numpy()), end='\\r')\n",
        "            \n",
        "def save_weights(model, model_weights_path):\n",
        "    weights = model.get_weights()\n",
        "    with open(model_weights_path, 'wb') as f:\n",
        "        pickle.dump(weights, f)\n"
      ],
      "metadata": {
        "id": "6nn9KuzXvKkq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class E2ESystemRLTraining(Model):\n",
        "\n",
        "    def __init__(self, speed, training):\n",
        "        super().__init__()\n",
        "\n",
        "        self._training = training\n",
        "\n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        self._binary_source = BinarySource()\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._encoder = LDPC5GEncoder(k, n)\n",
        "        # Trainable constellation\n",
        "        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n",
        "        self.constellation = constellation\n",
        "        self._mapper = Mapper(constellation=constellation)\n",
        "        \n",
        "        self._rg_mapper = ResourceGridMapper(resource_grid)\n",
        "\n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        #self._channel = AWGN()\n",
        "        # A 3GPP CDL channel model is used\n",
        "        cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n",
        "                  ut_antenna, bs_array, \"uplink\", min_speed=speed)\n",
        "        self._channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        # We use the previously defined neural network for demapping\n",
        "        self._demapper = NeuralDemapper()\n",
        "        \n",
        "        self._rg_demapper = ResourceGridDemapper(resource_grid, stream_manager) # Used to extract data-carrying resource elements\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
        "\n",
        "    #@tf.function\n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n",
        "\n",
        "        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n",
        "        if len(ebno_db.shape) == 0:\n",
        "            ebno_db = tf.fill([batch_size], ebno_db)\n",
        "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, resource_grid)\n",
        "        #no = expand_to_rank(no, 2)\n",
        "\n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        # Outer coding is only performed if not training\n",
        "        if self._training:\n",
        "            #c = self._binary_source([batch_size, n])\n",
        "            c = self._binary_source([batch_size, 1, 1, n])\n",
        "        else:\n",
        "            #b = self._binary_source([batch_size, k])\n",
        "            b = self._binary_source([batch_size, 1, 1, k])\n",
        "            c = self._encoder(b)\n",
        "        # Modulation\n",
        "        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n",
        "        x_rg = self._rg_mapper(x)\n",
        "        \n",
        "        # Adding perturbation\n",
        "        # If ``perturbation_variance`` is 0, then the added perturbation is null\n",
        "        # epsilon_r = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n",
        "        # epsilon_i = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n",
        "        # epsilon = tf.complex(epsilon_r, epsilon_i) # [batch size, num_symbols_per_codeword]\n",
        "        # x_p = x + epsilon # [batch size, num_symbols_per_codeword]\n",
        "        \n",
        "        epsilon_r = tf.random.normal(tf.shape(x_rg))*tf.sqrt(0.5*perturbation_variance)\n",
        "        epsilon_i = tf.random.normal(tf.shape(x_rg))*tf.sqrt(0.5*perturbation_variance)\n",
        "        epsilon = tf.complex(epsilon_r, epsilon_i) # [batch size, num_symbols_per_codeword]\n",
        "        x_p = x_rg + epsilon # [batch size, num_symbols_per_codeword]\n",
        "        \n",
        "\n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        no_ = expand_to_rank(no, tf.rank(x_p))\n",
        "        y = self._channel([x_p, no_]) # [batch size, num_symbols_per_codeword]\n",
        "        y = tf.stop_gradient(y) # Stop gradient here\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        #llr = self._demapper([y, no])\n",
        "        # The neural receover computes LLRs from the frequency domain received symbols and N0\n",
        "        y = tf.squeeze(y, axis=1)\n",
        "        llr = self._neural_receiver([y, no])\n",
        "        llr = insert_dims(llr, 2, 1) # Reshape the input to fit what the resource grid demapper is expected\n",
        "        llr = self._rg_demapper(llr) # Extract data-carrying resource elements. The other LLrs are discarded\n",
        "        llr = tf.reshape(llr, [batch_size, 1, 1, n]) # Reshape the LLRs to fit what the outer decoder is expected\n",
        "\n",
        "        # If training, outer decoding is not performed\n",
        "        if self._training:\n",
        "            # Average BCE for each baseband symbol and each batch example\n",
        "            c = tf.reshape(c, [-1, num_symbols_per_codeword, num_bits_per_symbol])\n",
        "            bce = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(c, llr), axis=2) # Avergare over the bits mapped to a same baseband symbol\n",
        "            # The RX loss is the usual average BCE\n",
        "            rx_loss = tf.reduce_mean(bce)\n",
        "            # From the TX side, the BCE is seen as a feedback from the RX through which backpropagation is not possible\n",
        "            bce = tf.stop_gradient(bce) # [batch size, num_symbols_per_codeword]\n",
        "            x_p = tf.stop_gradient(x_p)\n",
        "            p = x_p-x # [batch size, num_symbols_per_codeword] Gradient is backpropagated through `x`\n",
        "            tx_loss = tf.square(tf.math.real(p)) + tf.square(tf.math.imag(p)) # [batch size, num_symbols_per_codeword]\n",
        "            tx_loss = -bce*tx_loss/rl_perturbation_var # [batch size, num_symbols_per_codeword]\n",
        "            tx_loss = tf.reduce_mean(tx_loss)\n",
        "            return tx_loss, rx_loss\n",
        "        else:\n",
        "            llr = tf.reshape(llr, [-1, n]) # Reshape as expected by the outer decoder\n",
        "            b_hat = self._decoder(llr)\n",
        "            return b,b_hat\n",
        "        \n",
        "def rl_based_training(model):\n",
        "    # Optimizers used to apply gradients\n",
        "    optimizer_tx = tf.keras.optimizers.Adam() # For training the transmitter\n",
        "    optimizer_rx = tf.keras.optimizers.Adam() # For training the receiver\n",
        "\n",
        "    # Function that implements one transmitter training iteration using RL.\n",
        "    def train_tx():\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Keep only the TX loss\n",
        "            tx_loss, _ = model(training_batch_size, ebno_db,\n",
        "                               tf.constant(rl_perturbation_var, tf.float32)) # Perturbation are added to enable RL exploration\n",
        "        ## Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(tx_loss, weights)\n",
        "        optimizer_tx.apply_gradients(zip(grads, weights))\n",
        "\n",
        "    # Function that implements one receiver training iteration\n",
        "    def train_rx():\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Keep only the RX loss\n",
        "            _, rx_loss = model(training_batch_size, ebno_db) # No perturbation is added\n",
        "        ## Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(rx_loss, weights)\n",
        "        optimizer_rx.apply_gradients(zip(grads, weights))\n",
        "        # The RX loss is returned to print the progress\n",
        "        return rx_loss\n",
        "\n",
        "    # Training loop.\n",
        "    for i in range(num_training_iterations_rl_alt):\n",
        "        # 10 steps of receiver training are performed to keep it ahead of the transmitter\n",
        "        # as it is used for computing the losses when training the transmitter\n",
        "        for _ in range(10):\n",
        "            rx_loss = train_rx()\n",
        "        # One step of transmitter training\n",
        "        train_tx()\n",
        "        # Printing periodically the progress\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_alt, rx_loss.numpy()), end='\\r')\n",
        "    print() # Line break\n",
        "\n",
        "    # Once alternating training is done, the receiver is fine-tuned.\n",
        "    print('Receiver fine-tuning... ')\n",
        "    for i in range(num_training_iterations_rl_finetuning):\n",
        "        rx_loss = train_rx()\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_finetuning, rx_loss.numpy()), end='\\r')\n",
        "            \n"
      ],
      "metadata": {
        "id": "AGVxz2Z3vUes"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline(Model):\n",
        "\n",
        "    def __init__(self, speed):\n",
        "        super().__init__()\n",
        "\n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        self._binary_source = BinarySource()\n",
        "        self._encoder = LDPC5GEncoder(k, n)\n",
        "        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=False)\n",
        "        self.constellation = constellation\n",
        "        self._mapper = Mapper(constellation=constellation)\n",
        "        \n",
        "        self._rg_mapper = ResourceGridMapper(resource_grid)\n",
        "\n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        #self._channel = AWGN()\n",
        "        # A 3GPP CDL channel model is used\n",
        "        cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n",
        "                  ut_antenna, bs_array, \"uplink\", min_speed=speed)\n",
        "        self._channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        self._removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n",
        "        \n",
        "        self._demapper = Demapper(\"app\", constellation=constellation)\n",
        "        self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
        "\n",
        "    #@tf.function\n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n",
        "\n",
        "        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n",
        "        if len(ebno_db.shape) == 0:\n",
        "            ebno_db = tf.fill([batch_size], ebno_db)\n",
        "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, resource_grid)\n",
        "        #no = expand_to_rank(no, 2)\n",
        "\n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        #b = self._binary_source([batch_size, k])\n",
        "        b = self._binary_source([batch_size, 1, 1, k])\n",
        "        c = self._encoder(b)\n",
        "        # Modulation\n",
        "        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n",
        "        \n",
        "        x_rg = self._rg_mapper(x)\n",
        "\n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        # A batch of new channel realizations is sampled and applied at every inference\n",
        "        no_ = expand_to_rank(no, tf.rank(x_rg))\n",
        "        y,h = self._channel([x_rg, no_]) # [batch size, num_symbols_per_codeword]\n",
        "        #y = self._channel([x, no]) # [batch size, num_symbols_per_codeword]\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        h_hat = self._removed_null_subc(h) # Extract non-null subcarriers\n",
        "        err_var = 0.0 # No channel estimation error when perfect CSI knowledge is assumed\n",
        "        x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no]) # LMMSE equalization\n",
        "        no_eff_= expand_to_rank(no_eff, tf.rank(x_hat))\n",
        "        llr = self._demapper([x_hat, no_eff_])\n",
        "        \n",
        "        # Outer decoding\n",
        "        b_hat = self._decoder(llr)\n",
        "        return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n",
        "    \n",
        "# Utility function to load and set weights of a model\n",
        "def load_weights(model, model_weights_path):\n",
        "    model(1, tf.constant(10.0, tf.float32))\n",
        "    with open(model_weights_path, 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    model.set_weights(weights)\n",
        "\n"
      ],
      "metadata": {
        "id": "xviFlqnOv9IX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# system evaluation\n",
        "# Range of SNRs over which the systems are evaluated\n",
        "ebno_dbs = np.arange(ebno_db_min, # Min SNR for evaluation\n",
        "                     ebno_db_max, # Max SNR for evaluation\n",
        "                     0.5) # Step\n",
        "\n",
        "\n",
        "# Dictionnary storing the results\n",
        "BLER = {}\n",
        "\n",
        "MOBILITY_SIMS = {\n",
        "    \"speed\" : [15] #[0.0, 15.0, 30.0]\n",
        "}\n",
        "\n",
        "for speed in MOBILITY_SIMS[\"speed\"]:\n",
        "    # train models\n",
        "    # Fix the seed for reproducible trainings\n",
        "    tf.random.set_seed(1)\n",
        "    # Instantiate and train the end-to-end system\n",
        "    model = E2ESystemConventionalTraining(speed=speed, training=True)\n",
        "    conventional_training(model)\n",
        "    # Save weights\n",
        "    save_weights(model, model_weights_path_conventional_training)\n",
        "    \n",
        "    # Fix the seed for reproducible trainings\n",
        "    tf.random.set_seed(1)\n",
        "    # Instantiate and train the end-to-end system\n",
        "    model = E2ESystemRLTraining(speed=speed, training=True)\n",
        "    rl_based_training(model)\n",
        "    # Save weights\n",
        "    save_weights(model, model_weights_path_rl_training)\n",
        "    \n",
        "    # deploy systems\n",
        "    model_baseline = Baseline(speed=speed)\n",
        "    _,bler = sim_ber(model_baseline, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=100)\n",
        "    BLER['baseline'] = bler.numpy()\n",
        "    \n",
        "    model_conventional = E2ESystemConventionalTraining(training=False)\n",
        "    load_weights(model_conventional, model_weights_path_conventional_training)\n",
        "    _,bler = sim_ber(model_conventional, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=100)\n",
        "    BLER['autoencoder-conv'] = bler.numpy()\n",
        "    \n",
        "    model_rl = E2ESystemRLTraining(training=False)\n",
        "    load_weights(model_rl, model_weights_path_rl_training)\n",
        "    _,bler = sim_ber(model_rl, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=100)\n",
        "    BLER['autoencoder-rl'] = bler.numpy()\n",
        "    \n",
        "    with open(results_filename, 'wb') as f:\n",
        "        pickle.dump((ebno_dbs, BLER), f)\n",
        "\n",
        "        \n",
        "plt.figure(figsize=(10,8))\n",
        "plt.xlabel(r\"$E_b/N_0$ (dB)\")\n",
        "plt.ylabel(\"BLER\")\n",
        "plt.grid(which=\"both\")\n",
        "\n",
        "for speed in MOBILITY_SIMS[\"speed\"]:\n",
        "    # Baseline - Perfect CSI\n",
        "    plt.semilogy(ebno_dbs, BLER['baseline'], 'o-', label='Baseline - {}[m/s]'.format(speed))\n",
        "    # Autoencoder - conventional training\n",
        "    plt.semilogy(ebno_dbs, BLER['autoencoder-conv'], 'x-.', label='Autoencoder - conventional training - {}[m/s]'.format(speed))\n",
        "    # Autoencoder - RL-based training\n",
        "    plt.semilogy(ebno_dbs, BLER['autoencoder-rl'], 'o-.', label='Autoencoder - RL-based training - {}[m/s]'.format(speed))\n",
        "\n",
        "plt.ylim((1e-4, 1.0))\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "#plt.title(\"3GPP CDL-{} Models {}GHz Uplink - Impact of Learning-based Channel Estimation across\".format(cdl_model, carrier_frequency/1e9));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "t0JKrrUIwbxr",
        "outputId": "dff57f33-6267-4a30-e893-6f4a50f0b929"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ec952bdf1fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Instantiate and train the end-to-end system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE2ESystemRLTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrl_based_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Save weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weights_path_rl_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-4921f37909e6>\u001b[0m in \u001b[0;36mrl_based_training\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# as it is used for computing the losses when training the transmitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mrx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;31m# One step of transmitter training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mtrain_tx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-4921f37909e6>\u001b[0m in \u001b[0;36mtrain_rx\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Keep only the RX loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebno_db\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# No perturbation is added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;31m## Computing and applying gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file7kfhpvhw.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, batch_size, ebno_db, perturbation_variance)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mno_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_to_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mllr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_receiver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"e2e_system_rl_training_1\" (type E2ESystemRLTraining).\n\nin user code:\n\n    File \"<ipython-input-19-4921f37909e6>\", line 87, in call  *\n        y = tf.stop_gradient(y) # Stop gradient here\n\n    ValueError: Tried to convert 'input' to a tensor and failed. Error: Shapes must be equal rank, but are 5 and 7\n    \tFrom merging shape 0 with other shapes. for '{{node StopGradient/packed}} = Pack[N=2, T=DT_COMPLEX64, axis=0](ofdm_channel_3/apply_ofdm_channel/awgn/add_3, ofdm_channel_3/truediv_30)' with input shapes: [128,1,2,14,128], [?,1,2,1,1,14,128].\n\n\nCall arguments received by layer \"e2e_system_rl_training_1\" (type E2ESystemRLTraining):\n  • batch_size=tf.Tensor(shape=(), dtype=int32)\n  • ebno_db=tf.Tensor(shape=(128,), dtype=float32)\n  • perturbation_variance=0.0"
          ]
        }
      ]
    }
  ]
}